{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Data is [fetched from the Api](api_.py) socket provided, https://services.nvd.nist.gov/rest/json/cves/1.0/. \n",
    "\n",
    "A local [MongoDB is established](mongo_.py) and the data is upserted. \n",
    "\n",
    "With [mongo queries](pddf.py) the data is unraveled, split into two, for CVSSv2 and CVSSv3. It is then returned as pandas' dataframes.\n",
    "\n",
    "The `Run()` class will perform all this with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from run import Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish and Fill MongoDB\n",
    "Connects to the API and builds succesive queries by default starting in 2014 waiting 1s between each query.\n",
    "\n",
    "Upserts to a local MongoDB established with default settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-01-01T00:00:00:000%20UTC-00:00&pubEndDate=2014-05-01T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2205\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-01-01T00:00:00:000%20UTC-00:00&pubEndDate=2014-05-01T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2205 /2205 \n",
      "0 documents added to  collection,  2205 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-05-01T00:00:00:000%20UTC-00:00&pubEndDate=2014-08-29T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2018\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-05-01T00:00:00:000%20UTC-00:00&pubEndDate=2014-08-29T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2018 /2018 \n",
      "0 documents added to  collection,  2018 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-08-29T00:00:00:000%20UTC-00:00&pubEndDate=2014-12-27T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /3638\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-08-29T00:00:00:000%20UTC-00:00&pubEndDate=2014-12-27T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 3638 /3638 \n",
      "3638 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-12-27T00:00:00:000%20UTC-00:00&pubEndDate=2015-04-26T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2223\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2014-12-27T00:00:00:000%20UTC-00:00&pubEndDate=2015-04-26T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2223 /2223 \n",
      "2223 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2015-04-26T00:00:00:000%20UTC-00:00&pubEndDate=2015-08-24T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2056\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2015-04-26T00:00:00:000%20UTC-00:00&pubEndDate=2015-08-24T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2056 /2056 \n",
      "2056 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2015-08-24T00:00:00:000%20UTC-00:00&pubEndDate=2015-12-22T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2157\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2015-08-24T00:00:00:000%20UTC-00:00&pubEndDate=2015-12-22T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2157 /2157 \n",
      "2157 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2015-12-22T00:00:00:000%20UTC-00:00&pubEndDate=2016-04-20T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "harvested : 1914 /1914 \n",
      "1914 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-04-20T00:00:00:000%20UTC-00:00&pubEndDate=2016-08-18T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2390\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-04-20T00:00:00:000%20UTC-00:00&pubEndDate=2016-08-18T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2390 /2390 \n",
      "2390 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-08-18T00:00:00:000%20UTC-00:00&pubEndDate=2016-12-16T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2057\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-08-18T00:00:00:000%20UTC-00:00&pubEndDate=2016-12-16T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2057 /2057 \n",
      "2057 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-12-16T00:00:00:000%20UTC-00:00&pubEndDate=2017-04-15T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /4500\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-12-16T00:00:00:000%20UTC-00:00&pubEndDate=2017-04-15T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /4500\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2016-12-16T00:00:00:000%20UTC-00:00&pubEndDate=2017-04-15T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 4500 /4500 \n",
      "4500 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-04-15T00:00:00:000%20UTC-00:00&pubEndDate=2017-08-13T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /4843\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-04-15T00:00:00:000%20UTC-00:00&pubEndDate=2017-08-13T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /4843\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-04-15T00:00:00:000%20UTC-00:00&pubEndDate=2017-08-13T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 4843 /4843 \n",
      "4843 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-08-13T00:00:00:000%20UTC-00:00&pubEndDate=2017-12-11T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /4751\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-08-13T00:00:00:000%20UTC-00:00&pubEndDate=2017-12-11T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /4751\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-08-13T00:00:00:000%20UTC-00:00&pubEndDate=2017-12-11T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 4751 /4751 \n",
      "4751 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-12-11T00:00:00:000%20UTC-00:00&pubEndDate=2018-04-10T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /5164\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-12-11T00:00:00:000%20UTC-00:00&pubEndDate=2018-04-10T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /5164\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2017-12-11T00:00:00:000%20UTC-00:00&pubEndDate=2018-04-10T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 5164 /5164 \n",
      "5164 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-04-10T00:00:00:000%20UTC-00:00&pubEndDate=2018-08-08T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /6597\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-04-10T00:00:00:000%20UTC-00:00&pubEndDate=2018-08-08T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /6597\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-04-10T00:00:00:000%20UTC-00:00&pubEndDate=2018-08-08T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /6597\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-04-10T00:00:00:000%20UTC-00:00&pubEndDate=2018-08-08T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 6597 /6597 \n",
      "6597 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-08-08T00:00:00:000%20UTC-00:00&pubEndDate=2018-12-06T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /4521\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-08-08T00:00:00:000%20UTC-00:00&pubEndDate=2018-12-06T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /4521\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-08-08T00:00:00:000%20UTC-00:00&pubEndDate=2018-12-06T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 4521 /4521 \n",
      "4521 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-12-06T00:00:00:000%20UTC-00:00&pubEndDate=2019-04-05T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /4614\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-12-06T00:00:00:000%20UTC-00:00&pubEndDate=2019-04-05T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /4614\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2018-12-06T00:00:00:000%20UTC-00:00&pubEndDate=2019-04-05T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 4614 /4614 \n",
      "4614 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-04-05T00:00:00:000%20UTC-00:00&pubEndDate=2019-08-03T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /5674\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-04-05T00:00:00:000%20UTC-00:00&pubEndDate=2019-08-03T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /5674\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-04-05T00:00:00:000%20UTC-00:00&pubEndDate=2019-08-03T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 5674 /5674 \n",
      "5674 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-08-03T00:00:00:000%20UTC-00:00&pubEndDate=2019-12-01T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /6432\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-08-03T00:00:00:000%20UTC-00:00&pubEndDate=2019-12-01T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /6432\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-08-03T00:00:00:000%20UTC-00:00&pubEndDate=2019-12-01T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /6432\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-08-03T00:00:00:000%20UTC-00:00&pubEndDate=2019-12-01T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 6432 /6432 \n",
      "6432 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-12-01T00:00:00:000%20UTC-00:00&pubEndDate=2020-03-30T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /6318\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-12-01T00:00:00:000%20UTC-00:00&pubEndDate=2020-03-30T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /6318\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-12-01T00:00:00:000%20UTC-00:00&pubEndDate=2020-03-30T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /6318\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2019-12-01T00:00:00:000%20UTC-00:00&pubEndDate=2020-03-30T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 6318 /6318 \n",
      "6318 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-03-30T00:00:00:000%20UTC-00:00&pubEndDate=2020-07-28T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /6241\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-03-30T00:00:00:000%20UTC-00:00&pubEndDate=2020-07-28T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /6241\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-03-30T00:00:00:000%20UTC-00:00&pubEndDate=2020-07-28T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /6241\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-03-30T00:00:00:000%20UTC-00:00&pubEndDate=2020-07-28T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 6241 /6241 \n",
      "6241 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-07-28T00:00:00:000%20UTC-00:00&pubEndDate=2020-11-25T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /5692\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-07-28T00:00:00:000%20UTC-00:00&pubEndDate=2020-11-25T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /5692\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-07-28T00:00:00:000%20UTC-00:00&pubEndDate=2020-11-25T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 5692 /5692 \n",
      "5692 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-11-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-03-25T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /5753\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-11-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-03-25T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /5753\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2020-11-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-03-25T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "harvested : 5753 /5753 \n",
      "5753 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-03-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-07-23T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /6676\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-03-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-07-23T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /6676\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-03-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-07-23T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /6676\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-03-25T00:00:00:000%20UTC-00:00&pubEndDate=2021-07-23T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 6676 /6676 \n",
      "6676 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-07-23T00:00:00:000%20UTC-00:00&pubEndDate=2021-11-20T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /7083\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-07-23T00:00:00:000%20UTC-00:00&pubEndDate=2021-11-20T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /7083\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-07-23T00:00:00:000%20UTC-00:00&pubEndDate=2021-11-20T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /7083\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-07-23T00:00:00:000%20UTC-00:00&pubEndDate=2021-11-20T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 7083 /7083 \n",
      "7083 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-11-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-03-20T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /7581\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-11-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-03-20T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "starting at: 4000 /7581\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-11-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-03-20T00:00:00:000%20UTC-00:00&startIndex=4000&resultsPerPage=2000\n",
      "starting at: 6000 /7581\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2021-11-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-03-20T00:00:00:000%20UTC-00:00&startIndex=6000&resultsPerPage=2000\n",
      "harvested : 7581 /7581 \n",
      "7581 documents added to  collection,  0 already exist\n",
      "waiting 1s ...\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2022-03-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-07-18T00:00:00:000%20UTC-00:00&resultsPerPage=2000\n",
      "starting at: 2000 /2164\n",
      "https://services.nvd.nist.gov/rest/json/cves/1.0/?pubStartDate=2022-03-20T00:00:00:000%20UTC-00:00&pubEndDate=2022-07-18T00:00:00:000%20UTC-00:00&startIndex=2000&resultsPerPage=2000\n",
      "harvested : 2164 /2164 \n",
      "2164 documents added to  collection,  0 already exist\n",
      "In total, 111039 added and 4223 already exist in tenable_db.t\n",
      "115262 files in collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<run.Run at 0x7fffa9b565b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#NOTE: will automatically start downloading and\n",
    "# try to connect to a default mongoDB client\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "Run(collection='t').fill_mongo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "Explore the data to get a better understanding of the content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Pandas' dataframes\n",
    "Two df's returned for CVSSv2 and v3 which are merged together using an outer join\n",
    "\n",
    "- Create a Data frame with one row per CVE id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = Run(collection= 't').fill_df()\n",
    "dfV2,dfV3 = dfs.dfV2,dfs.dfV3\n",
    "try:\n",
    "    df = pd.merge( dfV3, dfV2, 'outer', '_id',suffixes=['_V3', '_V2'])\n",
    "except:\n",
    "    print('''ERROR: Possibly no MongoDB loaded\\nCreating df from backupDB.csv''')\n",
    "    pd.read_csv('backupDB.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many CVEs have CVSSv3 metrics versus only CVSSv2 metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n of CVE's = 115262\n",
      "with CVSSv3 = 100248\n",
      "with CVSSv2 = 114569\n",
      "with just CVSSv2 = 14420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Total n of CVE's = {len(df)}\n",
    "with CVSSv3 = {len(df.vectorString_V3.dropna())}\n",
    "with CVSSv2 = {len(df.vectorString_V2.dropna())}\n",
    "with just CVSSv2 = {len((df[df['vectorString_V3'].isnull()])['vectorString_V2'].dropna())}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for unique values in each column to determine if categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan '3.1' '3.0'] version_V3\n",
      "[nan 'NETWORK' 'LOCAL' 'PHYSICAL' 'ADJACENT_NETWORK'] attackVector\n",
      "[nan 'LOW' 'HIGH'] attackComplexity\n",
      "[nan 'NONE' 'LOW' 'HIGH'] privilegesRequired\n",
      "[nan 'NONE' 'REQUIRED'] userInteraction\n",
      "[nan 'UNCHANGED' 'CHANGED'] scope\n",
      "[nan 'HIGH' 'LOW' 'NONE'] confidentialityImpact_V3\n",
      "[nan 'HIGH' 'LOW' 'NONE'] integrityImpact_V3\n",
      "[nan 'HIGH' 'NONE' 'LOW'] availabilityImpact_V3\n",
      "[nan 'CRITICAL' 'MEDIUM' 'HIGH' 'LOW'] baseSeverity\n",
      "['2.0' nan] version_V2\n",
      "['NETWORK' 'LOCAL' 'ADJACENT_NETWORK' nan] accessVector\n",
      "['LOW' 'MEDIUM' 'HIGH' nan] accessComplexity\n",
      "['NONE' 'SINGLE' 'MULTIPLE' nan] authentication\n",
      "['NONE' 'PARTIAL' 'COMPLETE' nan] confidentialityImpact_V2\n",
      "['PARTIAL' 'NONE' 'COMPLETE' nan] integrityImpact_V2\n",
      "['NONE' 'PARTIAL' 'COMPLETE' nan] availabilityImpact_V2\n",
      "['MEDIUM' 'HIGH' 'LOW' nan] severity\n",
      "[False True nan] obtainAllPrivilege\n",
      "[False True nan] obtainUserPrivilege\n",
      "[False True nan] obtainOtherPrivilege\n",
      "[False True nan] userInteractionRequired\n",
      "[nan False True] acInsufInfo\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtype == object and len(df[i].unique()) <10:\n",
    "        print (df[i].unique(), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`attackVector` and `accessVector` are nominal categorical and need dummy variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δ_list = [['attackVector','AV_3'], ['accessVector', 'AV_2']]\n",
    "dum_add = lambda ele: pd.get_dummies(df[ele[0]],prefix=ele[1])\n",
    "\n",
    "frames = [dum_add(i) for i in Δ_list]\n",
    "\n",
    "df = df.drop([i[0] for i in Δ_list], axis=1)\n",
    "\n",
    "frames.append(df)\n",
    "\n",
    "df = pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "the other columns are ordinal categorical(e.g. `LOW`, `MEDIUM`, `HIGH` ) or boolean and can be filled with a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {'NONE': 0, 'LOW':1, 'MEDIUM':2,'HIGH':3, 'CRITICAL':4,\n",
    "'PARTIAL': 1, 'COMPLETE':2,\n",
    "'SINGLE' :1, 'MULTIPLE' :2,\n",
    "'UNCHANGED':0 ,'CHANGED':1,\n",
    "'REQUIRED':1,\n",
    "False:0, True:1\n",
    "}\n",
    "df.replace(cat_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating general index of all keys for manipulating columns and adds the new dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfV2_keys,dfV3_keys = dfs.dfV2.keys(),dfs.dfV3.keys()\n",
    "\n",
    "\n",
    "transform_idx = df.T.index\n",
    "\n",
    "for i in transform_idx:\n",
    "    #print(i[:4])\n",
    "    if i[:4] == 'AV_3':\n",
    "        dfV3_keys = dfV3_keys.append(pd.Index([i]))\n",
    "    if i[:4] == 'AV_2':\n",
    "        dfV2_keys = dfV2_keys.append(pd.Index([i]))\n",
    "\n",
    "dfV3_keys = dfV3_keys.drop('attackVector')\n",
    "dfV2_keys = dfV2_keys.drop('accessVector')\n",
    "\n",
    "setDf = dfV3_keys.union(dfV2_keys)#set(dfV3_keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating an index of all columns that appear in both CVSSv2 and v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxPairs = []\n",
    "\n",
    "for i in setDf: \n",
    "    substr_i = transform_idx[transform_idx.str.startswith(i+'_')]\n",
    "    if len(substr_i) >0:\n",
    "        idxPairs.append(substr_i)\n",
    "    \n",
    "\n",
    "#idxPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df.filter(regex='version*').columns\n",
    "df[f] = df[f].astype(float)\n",
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both CVSSv2 and CVSSv3 have the same set of impact metrics, i.e. Confidentiality, Integrity and Availability, however their values are slightly different. For example, CVSSv2 uses complete (C) to represent the highest level of impact, but CVSSv3 uses high (H) instead. Is it possible to directly map from CVSSv2 impact metric values to CVSSv3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024715511898207\n",
      "0.7847626572053179\n",
      "0.8352650731843352\n"
     ]
    }
   ],
   "source": [
    "for i in ['confidentialityImpact','integrityImpact','availabilityImpact']:\n",
    "    print(df.corr()[i+'_V2'][i+'_V3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correleation matrix between versions of the suggested metrics is not = 1, it would NOT be a good idea to directly map them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "predict the CVSSv3 Scope metric for CVEs without a CVSSv3 vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What type of learning problem is this? What is the target? \n",
    "\n",
    "This is a supervised classification problem with a single variable `scope` as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selects and combines the metrics of interest from previous indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cvssV3 = []\n",
    "cvssV2 = []\n",
    "dfV3_keys_cp = dfV3_keys.drop(['_id','vectorString'])\n",
    "dfV2_keys_cp = dfV2_keys.drop(['_id','vectorString'])\n",
    "for i in idxPairs:\n",
    "    if i[0][:-3] in dfV3_keys and i[0][:-3] != 'vectorString':\n",
    "        cvssV3.append(i[0])\n",
    "        dfV3_keys_cp = dfV3_keys_cp.drop([i[0][:-3]])\n",
    "\n",
    "    \n",
    "    if i[0][:-3] in dfV2_keys and i[0][:-3] != 'vectorString':\n",
    "        cvssV2.append(i[1])\n",
    "        dfV2_keys_cp = dfV2_keys_cp.drop([i[0][:-3]])\n",
    "\n",
    "cvssV3 = dfV3_keys_cp.union(cvssV3)  \n",
    "cvssV2 = dfV2_keys_cp.union(cvssV2)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copies the main df, selecting all columns and then dropping types = object (relevant data have dtype float, int,etc), the column `acInsufInfo` and all remaining rows with NaN's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoNan = df.loc[:,df.dtypes != 'object'].drop('acInsufInfo',axis=1).dropna()\n",
    "\n",
    "X_pt2 = dfNoNan[cvssV2.drop('acInsufInfo')]\n",
    "y_pt2 = dfNoNan['scope'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How would you build the training / validation / testing dataset?\n",
    "\n",
    "Take a random subset of the data and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt2_train, X_pt2_test, y_pt2_train, y_pt2_test = train_test_split(X_pt2, y_pt2, test_size= .33) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intended to scale data however all iterations tried made little difference on this dataset, possibly due to high n of categorical inputs and low variance in numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#X_pt2_train = sc.fit_transform(X_pt2_train)\n",
    "#X_pt2_test = sc.transform(X_pt2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percentage of total scope count that is = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20283647096936755"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scope.value_counts()[1]/df.scope.value_counts()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which evaluation metrics would you use?\n",
    "\n",
    "a helper function which takes in a model, fits it with train values, predicts the test values and checks it against the y test values returning a dict of all results.\n",
    "\n",
    "NOTE: for compatibility with multioutput models, a custom score() function is defined later on and a value of 0 is given for a multioutput confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_info(model,X,y):\n",
    "    #takes model, set of X, set of y\n",
    "    #returns dict\n",
    "    X_train, X_test = X\n",
    "    y_train, y_test = y\n",
    "    print('~~~ fitting model')\n",
    "    f = model.fit(X_train.values, y_train.values)\n",
    "    print('~~~ predicting values')\n",
    "    ŷ = model.predict(X_test.values)\n",
    "    print('~~~ checking validity')\n",
    "    \n",
    "    try:\n",
    "        sc = f.score(X_test.values, y_test.values)\n",
    "    except:\n",
    "        sc= score(X_test.values, y_test.values)\n",
    "    \n",
    "    m = mean_absolute_error(y_test.values, ŷ)\n",
    "    c = confusion_matrix(y_test.values, ŷ) if len(y_train.shape) == 1 else 0\n",
    "\n",
    "    dict_ = {'model': f, 'score' : sc, 'prediction': ŷ, 'MAE' : m, 'Confusion Matrix': c}\n",
    "    return dict_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "builds a dict of all the model dicts with model name as key and an index corresponding to model list location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_dict(mod_list,X,Y):\n",
    "    #takes a list of models,set of X, set of y\n",
    "    #returns dict\n",
    "    mod_dict ={}\n",
    "    idx = 0\n",
    "    for i in mod_list: \n",
    "        mod_type = i.__str__()\n",
    "        print(f\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~\\nWorking on {mod_type}\")\n",
    "        if len(Y[0].shape) > 1:\n",
    "            mod_info = model_info(MultiOutputRegressor(i),X,Y)\n",
    "        mod_info = model_info(i,X,Y)\n",
    "        mod_dict[mod_type] =  (idx ,mod_info)\n",
    "        idx+=1\n",
    "        pprint(mod_info)\n",
    "        \n",
    "    return mod_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- What simple model might be used for this problem? Could this be improved upon with a more complex solution?\n",
    "\n",
    "The Random Forest Classifier is repeatedly the best performer here. Ensemble Learning would be a good canditate here for improving on the given results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on MLPClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26633,   592],\n",
      "       [ 1198,  4334]]),\n",
      " 'MAE': 0.0546448087431694,\n",
      " 'model': MLPClassifier(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.9453551912568307}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on LogisticRegression()\n",
      "~~~ fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potz/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26475,   750],\n",
      "       [ 1529,  4003]]),\n",
      " 'MAE': 0.0695729157126721,\n",
      " 'model': LogisticRegression(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.9304270842873279}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on LinearDiscriminantAnalysis()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26042,  1183],\n",
      "       [ 1152,  4380]]),\n",
      " 'MAE': 0.07128247397502824,\n",
      " 'model': LinearDiscriminantAnalysis(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.9287175260249717}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on KNeighborsClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26626,   599],\n",
      "       [ 1232,  4300]]),\n",
      " 'MAE': 0.055896449613823,\n",
      " 'model': KNeighborsClassifier(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.944103550386177}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on DecisionTreeClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26621,   604],\n",
      "       [ 1199,  4333]]),\n",
      " 'MAE': 0.05504167048264493,\n",
      " 'model': DecisionTreeClassifier(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.944958329517355}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on RandomForestClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[26617,   608],\n",
      "       [ 1198,  4334]]),\n",
      " 'MAE': 0.05513325396098544,\n",
      " 'model': RandomForestClassifier(),\n",
      " 'prediction': array([0, 0, 0, ..., 0, 0, 0]),\n",
      " 'score': 0.9448667460390145}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on GaussianNB()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': array([[17813,  9412],\n",
      "       [  869,  4663]]),\n",
      " 'MAE': 0.31385658027291874,\n",
      " 'model': GaussianNB(),\n",
      " 'prediction': array([0, 0, 1, ..., 0, 0, 1]),\n",
      " 'score': 0.6861434197270813}\n"
     ]
    }
   ],
   "source": [
    "model_RFC = RandomForestClassifier()\n",
    "model_SVC = svm.SVC()\n",
    "model_MLP = MLPClassifier()\n",
    "model_LR =  LogisticRegression()\n",
    "model_LDA =  LinearDiscriminantAnalysis()\n",
    "model_KNN =  KNeighborsClassifier()\n",
    "model_CART =  DecisionTreeClassifier()\n",
    "model_NB =  GaussianNB()\n",
    "\n",
    "mod_list_pt2 = [\n",
    "    \n",
    "    #model_SVC,#slow\n",
    "    model_MLP,\n",
    "    model_LR,\n",
    "    model_LDA,\n",
    "    model_KNN,\n",
    "    model_CART,\n",
    "    model_RFC,\n",
    "    model_NB\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "mod_dict_pt2 = model_dict(mod_list_pt2,[X_pt2_train,X_pt2_test], [y_pt2_train,y_pt2_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ŷ dict built from the model dict for easier access to ŷ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPClassifier()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'LogisticRegression()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'LinearDiscriminantAnalysis()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'KNeighborsClassifier()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'DecisionTreeClassifier()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'RandomForestClassifier()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  0\n",
       " \n",
       " [32757 rows x 1 columns],\n",
       " 'GaussianNB()':        0\n",
       " 0      0\n",
       " 1      0\n",
       " 2      1\n",
       " 3      0\n",
       " 4      1\n",
       " ...   ..\n",
       " 32752  0\n",
       " 32753  1\n",
       " 32754  0\n",
       " 32755  0\n",
       " 32756  1\n",
       " \n",
       " [32757 rows x 1 columns]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ŷ_test_dict(mod_dict):\n",
    "    ŷtest_dict = {}\n",
    "    for i in mod_dict:\n",
    "        ŷ = pd.DataFrame(mod_dict[i][1]['prediction'])\n",
    "        ŷtest_dict[i.__str__()] =  ŷ\n",
    "    return ŷtest_dict\n",
    "ŷ_pt2_test_vals = ŷ_test_dict(mod_dict_pt2)\n",
    "\n",
    "ŷ_pt2_test_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.9453551912568307)\n"
     ]
    }
   ],
   "source": [
    "def best_model_chk(mod_dict):\n",
    "    #takes model dict \n",
    "    #returns tuple of index and model score \n",
    "    best_mod= ('',0)\n",
    "    for i in mod_dict:\n",
    "        presc = mod_dict[i][1]['score']\n",
    "        sc = np.average(presc) #if isinstance(presc,(int,float)) else np.average(presc)\n",
    "        if sc > best_mod[1]:\n",
    "            best_mod = mod_dict[i][0], mod_dict[i][1]['score']\n",
    "\n",
    "    print(best_mod)\n",
    "    return best_mod\n",
    "work_model_pt2 = mod_list_pt2[best_model_chk(mod_dict_pt2)[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterates through all models in the list and produces a dict of results with model name as key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_pt2_vals = {}\n",
    "for i in mod_list_pt2:\n",
    "    ŷ_pt2 = pd.DataFrame(i.predict(Xnew_pt2.values))\n",
    "    ŷ_pt2_vals[i.__str__()] = ŷ_pt2.value_counts(), ŷ_pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16977886977886977\n",
      "0.16767495094833224\n",
      "0.18521284540702015\n",
      "0.16311074918566776\n",
      "0.17044988937146605\n",
      "0.17169811320754716\n",
      "0.5960442507542743\n"
     ]
    }
   ],
   "source": [
    "for i in ŷ_pt2_vals:\n",
    "    print(ŷ_pt2_vals[i][0][1]/ŷ_pt2_vals[i][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selects data where scope = nan\n",
    "\n",
    "selects all columns with v2 data except for `acInsufInfo` and drops rows with nan\n",
    "\n",
    "predicts ŷ based on the best model picked from prev function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12210\n",
       "1     2073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_pt2 = df[df['scope'].isna()]\n",
    "\n",
    "Xnew_pt2 = df_y_pt2[cvssV2.drop('acInsufInfo')].dropna()\n",
    "\n",
    "ŷ_pt2 = pd.DataFrame(work_model_pt2.predict(Xnew_pt2.values))\n",
    "\n",
    "ŷ_pt2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted `scope` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14279</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14280</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14281</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14283 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "...   ..\n",
       "14278  1\n",
       "14279  0\n",
       "14280  0\n",
       "14281  0\n",
       "14282  1\n",
       "\n",
       "[14283 rows x 1 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ_pt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 3\n",
    "Predict the CVSSv3 Confidentiality, Integrity and Availability metrics for CVEs without a CVSSv3 vector.\n",
    "- What type of learning problem is this? What is the target? \n",
    "\n",
    "\n",
    "This is a multi output supervised regression problem with 3 targets, `confidentialityImpact_V3`, `integrityImpact_V3`, `availabilityImpact_V3`\n",
    "\n",
    "each target is calculated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_RFR = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list_pt3 = [\n",
    "    \n",
    "    model_RFR,\n",
    "    #model_KNN,#slow\n",
    "    model_CART,\n",
    "    model_RFC,\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoNan = df.loc[:,df.dtypes != 'object'].drop('acInsufInfo',axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.Index(['confidentialityImpact_V3', 'integrityImpact_V3', 'availabilityImpact_V3'])\n",
    "X = dfNoNan[cvssV2.drop('acInsufInfo')]\n",
    "y = dfNoNan[response].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How would you build the training / validation / testing dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt3_train, X_pt3_test, y_pt3_train, y_pt3_test = train_test_split(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Which evaluation metrics would you use?\n",
    "\n",
    "this is a really simple metric based on the sklearn `model.score()` function which gets  1 - total correct divided by total n. My implementation will take multioutput and returns a vector of len(ŷ). Does NOT work for single target ŷ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test, ŷ): \n",
    "    #takes y known , ŷ\n",
    "    #returns arr with len(ŷ)\n",
    "\n",
    "    arr_1 = y_test\n",
    "    arr_2 = ŷ\n",
    "\n",
    "    if len(arr_1)!=len(arr_2):\n",
    "        print(len(arr_1), len(arr_2))\n",
    "        print('!!! NOT the same length !!!')\n",
    "        return\n",
    "\n",
    "    shape = arr_2.shape\n",
    " \n",
    "    truth_d = {True:[0]*shape[1], False:[0]*shape[1]}\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            truth_d[arr_1[i][j] == arr_2[i][j]][j] += 1\n",
    "\n",
    "    return [1 - truth_d[True][i]/ shape[0] for i in range(shape[1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- What simple model might be used for this problem? Could this be improved upon with a more complex solution?\n",
    "\n",
    "\n",
    "Here the Multioutput Regressor acts as a wrapper around estimators. This allows for direct regression of each individual estimator. as can be seen from the Random Forest Regressor prediction the output is continous\n",
    "\n",
    "a better approach would be to use a chained regressor which would chain each regression together in a conditinal manner i.e;   y1  , y2|ŷ1 ,  y3|( ŷ1 & ŷ2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on RandomForestRegressor()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': 0,\n",
      " 'MAE': 0.2139516741810863,\n",
      " 'model': RandomForestRegressor(),\n",
      " 'prediction': array([[2.87800719, 2.89397179, 2.88352969],\n",
      "       [0.04612574, 2.09162542, 0.03286848],\n",
      "       [0.82491744, 1.22633834, 0.01089177],\n",
      "       ...,\n",
      "       [0.        , 3.        , 0.        ],\n",
      "       [0.00967921, 0.00936455, 2.78942462],\n",
      "       [0.99544568, 1.02547445, 0.00934515]]),\n",
      " 'score': 0.8720832111398696}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on DecisionTreeClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': 0,\n",
      " 'MAE': 0.13543681495809157,\n",
      " 'model': DecisionTreeClassifier(),\n",
      " 'prediction': array([[3, 3, 3],\n",
      "       [0, 3, 0],\n",
      "       [1, 1, 0],\n",
      "       ...,\n",
      "       [0, 3, 0],\n",
      "       [0, 0, 3],\n",
      "       [1, 1, 0]]),\n",
      " 'score': [0.7858236621534493, 0.7338410702772404, 0.9339941972920697]}\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Working on RandomForestClassifier()\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "~~~ fitting model\n",
      "~~~ predicting values\n",
      "~~~ checking validity\n",
      "{'Confusion Matrix': 0,\n",
      " 'MAE': 0.13522189984955943,\n",
      " 'model': RandomForestClassifier(),\n",
      " 'prediction': array([[3, 3, 3],\n",
      "       [0, 3, 0],\n",
      "       [1, 1, 0],\n",
      "       ...,\n",
      "       [0, 3, 0],\n",
      "       [0, 0, 3],\n",
      "       [1, 1, 0]]),\n",
      " 'score': [0.7858236621534493, 0.7338410702772404, 0.9339941972920697]}\n"
     ]
    }
   ],
   "source": [
    "mod_dict_pt3 = model_dict(mod_list_pt3,[X_pt3_train,X_pt3_test], [y_pt3_train,y_pt3_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_pt3_test_vals = ŷ_test_dict(mod_dict_pt3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AV_3_ADJACENT_NETWORK</th>\n",
       "      <th>AV_3_LOCAL</th>\n",
       "      <th>AV_3_NETWORK</th>\n",
       "      <th>AV_3_PHYSICAL</th>\n",
       "      <th>AV_2_ADJACENT_NETWORK</th>\n",
       "      <th>AV_2_LOCAL</th>\n",
       "      <th>AV_2_NETWORK</th>\n",
       "      <th>_id</th>\n",
       "      <th>version_V3</th>\n",
       "      <th>vectorString_V3</th>\n",
       "      <th>...</th>\n",
       "      <th>availabilityImpact_V2</th>\n",
       "      <th>baseScore_V2</th>\n",
       "      <th>severity</th>\n",
       "      <th>exploitabilityScore_V2</th>\n",
       "      <th>impactScore_V2</th>\n",
       "      <th>obtainAllPrivilege</th>\n",
       "      <th>obtainUserPrivilege</th>\n",
       "      <th>obtainOtherPrivilege</th>\n",
       "      <th>userInteractionRequired</th>\n",
       "      <th>acInsufInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2013-5704</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2014-0054</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2013-7315</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2013-4152</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2013-6429</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2021-45876</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2022-1004</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2022-24126</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2022-24656</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CVE-2022-0415</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115262 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AV_3_ADJACENT_NETWORK  AV_3_LOCAL  AV_3_NETWORK  AV_3_PHYSICAL  \\\n",
       "0                           0           0             0              0   \n",
       "1                           0           0             0              0   \n",
       "2                           0           0             0              0   \n",
       "3                           0           0             0              0   \n",
       "4                           0           0             0              0   \n",
       "...                       ...         ...           ...            ...   \n",
       "115257                      0           0             1              0   \n",
       "115258                      0           0             1              0   \n",
       "115259                      0           0             1              0   \n",
       "115260                      0           0             1              0   \n",
       "115261                      0           0             1              0   \n",
       "\n",
       "        AV_2_ADJACENT_NETWORK  AV_2_LOCAL  AV_2_NETWORK             _id  \\\n",
       "0                           0           0             1   CVE-2013-5704   \n",
       "1                           0           0             1   CVE-2014-0054   \n",
       "2                           0           0             1   CVE-2013-7315   \n",
       "3                           0           0             1   CVE-2013-4152   \n",
       "4                           0           0             1   CVE-2013-6429   \n",
       "...                       ...         ...           ...             ...   \n",
       "115257                      0           0             1  CVE-2021-45876   \n",
       "115258                      0           0             1   CVE-2022-1004   \n",
       "115259                      0           0             1  CVE-2022-24126   \n",
       "115260                      0           0             1  CVE-2022-24656   \n",
       "115261                      0           0             1   CVE-2022-0415   \n",
       "\n",
       "        version_V3                               vectorString_V3  ...  \\\n",
       "0             <NA>                                          <NA>  ...   \n",
       "1             <NA>                                          <NA>  ...   \n",
       "2             <NA>                                          <NA>  ...   \n",
       "3             <NA>                                          <NA>  ...   \n",
       "4             <NA>                                          <NA>  ...   \n",
       "...            ...                                           ...  ...   \n",
       "115257         3.1  CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H  ...   \n",
       "115258         3.1  CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N  ...   \n",
       "115259         3.1  CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H  ...   \n",
       "115260         3.1  CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N  ...   \n",
       "115261         3.1  CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H  ...   \n",
       "\n",
       "        availabilityImpact_V2  baseScore_V2  severity  exploitabilityScore_V2  \\\n",
       "0                           0           5.0         2                    10.0   \n",
       "1                           1           6.8         2                     8.6   \n",
       "2                           1           6.8         2                     8.6   \n",
       "3                           1           6.8         2                     8.6   \n",
       "4                           1           6.8         2                     8.6   \n",
       "...                       ...           ...       ...                     ...   \n",
       "115257                      1           7.5         3                    10.0   \n",
       "115258                      0           4.0         2                     8.0   \n",
       "115259                      1           7.5         3                    10.0   \n",
       "115260                      0           4.3         2                     8.6   \n",
       "115261                      1           6.5         2                     8.0   \n",
       "\n",
       "        impactScore_V2  obtainAllPrivilege  obtainUserPrivilege  \\\n",
       "0                  2.9                   0                    0   \n",
       "1                  6.4                   0                    0   \n",
       "2                  6.4                   0                    0   \n",
       "3                  6.4                   0                    0   \n",
       "4                  6.4                   0                    0   \n",
       "...                ...                 ...                  ...   \n",
       "115257             6.4                   0                    0   \n",
       "115258             2.9                   0                    0   \n",
       "115259             6.4                   0                    0   \n",
       "115260             2.9                   0                    0   \n",
       "115261             6.4                   0                    0   \n",
       "\n",
       "        obtainOtherPrivilege  userInteractionRequired  acInsufInfo  \n",
       "0                          0                        0         <NA>  \n",
       "1                          0                        1         <NA>  \n",
       "2                          0                        0         <NA>  \n",
       "3                          0                        0         <NA>  \n",
       "4                          0                        1            0  \n",
       "...                      ...                      ...          ...  \n",
       "115257                     0                        0            0  \n",
       "115258                     0                        0            0  \n",
       "115259                     0                        0            0  \n",
       "115260                     0                        1            0  \n",
       "115261                     0                        0            0  \n",
       "\n",
       "[115262 rows x 37 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan here is as above select all response variables from the df that = NaN\n",
    "\n",
    "selects all columns with v2 data except for `acInsufInfo` and drop rows with nan\n",
    "\n",
    "predict ŷ based on the best model picked from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AV_3_ADJACENT_NETWORK</th>\n",
       "      <th>AV_3_LOCAL</th>\n",
       "      <th>AV_3_NETWORK</th>\n",
       "      <th>AV_3_PHYSICAL</th>\n",
       "      <th>AV_2_ADJACENT_NETWORK</th>\n",
       "      <th>AV_2_LOCAL</th>\n",
       "      <th>AV_2_NETWORK</th>\n",
       "      <th>_id</th>\n",
       "      <th>version_V3</th>\n",
       "      <th>vectorString_V3</th>\n",
       "      <th>...</th>\n",
       "      <th>availabilityImpact_V2</th>\n",
       "      <th>baseScore_V2</th>\n",
       "      <th>severity</th>\n",
       "      <th>exploitabilityScore_V2</th>\n",
       "      <th>impactScore_V2</th>\n",
       "      <th>obtainAllPrivilege</th>\n",
       "      <th>obtainUserPrivilege</th>\n",
       "      <th>obtainOtherPrivilege</th>\n",
       "      <th>userInteractionRequired</th>\n",
       "      <th>acInsufInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115257</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115258</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115259</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115260</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115261</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115262 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AV_3_ADJACENT_NETWORK  AV_3_LOCAL  AV_3_NETWORK  AV_3_PHYSICAL  \\\n",
       "0                        <NA>        <NA>          <NA>           <NA>   \n",
       "1                        <NA>        <NA>          <NA>           <NA>   \n",
       "2                        <NA>        <NA>          <NA>           <NA>   \n",
       "3                        <NA>        <NA>          <NA>           <NA>   \n",
       "4                        <NA>        <NA>          <NA>           <NA>   \n",
       "...                       ...         ...           ...            ...   \n",
       "115257                   <NA>        <NA>          <NA>           <NA>   \n",
       "115258                   <NA>        <NA>          <NA>           <NA>   \n",
       "115259                   <NA>        <NA>          <NA>           <NA>   \n",
       "115260                   <NA>        <NA>          <NA>           <NA>   \n",
       "115261                   <NA>        <NA>          <NA>           <NA>   \n",
       "\n",
       "        AV_2_ADJACENT_NETWORK  AV_2_LOCAL  AV_2_NETWORK   _id  version_V3  \\\n",
       "0                        <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "1                        <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "2                        <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "3                        <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "4                        <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "...                       ...         ...           ...   ...         ...   \n",
       "115257                   <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "115258                   <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "115259                   <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "115260                   <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "115261                   <NA>        <NA>          <NA>  <NA>        <NA>   \n",
       "\n",
       "       vectorString_V3  ...  availabilityImpact_V2  baseScore_V2  severity  \\\n",
       "0                 <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "1                 <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "2                 <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "3                 <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "4                 <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "...                ...  ...                    ...           ...       ...   \n",
       "115257            <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "115258            <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "115259            <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "115260            <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "115261            <NA>  ...                   <NA>          <NA>      <NA>   \n",
       "\n",
       "        exploitabilityScore_V2  impactScore_V2  obtainAllPrivilege  \\\n",
       "0                         <NA>            <NA>                <NA>   \n",
       "1                         <NA>            <NA>                <NA>   \n",
       "2                         <NA>            <NA>                <NA>   \n",
       "3                         <NA>            <NA>                <NA>   \n",
       "4                         <NA>            <NA>                <NA>   \n",
       "...                        ...             ...                 ...   \n",
       "115257                    <NA>            <NA>                <NA>   \n",
       "115258                    <NA>            <NA>                <NA>   \n",
       "115259                    <NA>            <NA>                <NA>   \n",
       "115260                    <NA>            <NA>                <NA>   \n",
       "115261                    <NA>            <NA>                <NA>   \n",
       "\n",
       "        obtainUserPrivilege  obtainOtherPrivilege  userInteractionRequired  \\\n",
       "0                      <NA>                  <NA>                     <NA>   \n",
       "1                      <NA>                  <NA>                     <NA>   \n",
       "2                      <NA>                  <NA>                     <NA>   \n",
       "3                      <NA>                  <NA>                     <NA>   \n",
       "4                      <NA>                  <NA>                     <NA>   \n",
       "...                     ...                   ...                      ...   \n",
       "115257                 <NA>                  <NA>                     <NA>   \n",
       "115258                 <NA>                  <NA>                     <NA>   \n",
       "115259                 <NA>                  <NA>                     <NA>   \n",
       "115260                 <NA>                  <NA>                     <NA>   \n",
       "115261                 <NA>                  <NA>                     <NA>   \n",
       "\n",
       "        acInsufInfo  \n",
       "0              <NA>  \n",
       "1              <NA>  \n",
       "2              <NA>  \n",
       "3              <NA>  \n",
       "4              <NA>  \n",
       "...             ...  \n",
       "115257         <NA>  \n",
       "115258         <NA>  \n",
       "115259         <NA>  \n",
       "115260         <NA>  \n",
       "115261         <NA>  \n",
       "\n",
       "[115262 rows x 37 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#NOTE: NOT working, having difficulty getting the right pandas indexing \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df_y_pt3 = df[df[response ].isna()]\n",
    "df_y_pt3#.value_counts()\n",
    "\n",
    "#df[df[['confidentialityImpact_V3', 'integrityImpact_V3', 'availabilityImpact_V3']].isnull()]\n",
    "\n",
    "#Xnew_pt3 = df_y_pt3[cvssV2.drop('acInsufInfo')].dropna()\n",
    "\n",
    "#ŷ_pt3 = pd.DataFrame(work_model_pt3.predict(Xnew_pt3.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
